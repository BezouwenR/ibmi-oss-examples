{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import backend\n",
    "from chainer import backends\n",
    "from chainer.backends import cuda\n",
    "from chainer import Function, FunctionNode, gradient_check, report, training, utils, Variable\n",
    "from chainer import datasets, initializers, iterators, optimizers, serializers\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer.training import extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.datasets import mnist\n",
    "\n",
    "train, test = mnist.get_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(Chain):\n",
    "\n",
    "    def __init__(self, n_mid_units=100, n_out=10):\n",
    "        super(MLP, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.l1 = L.Linear(None, n_mid_units)\n",
    "            self.l2 = L.Linear(None, n_mid_units)\n",
    "            self.l3 = L.Linear(None, n_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "gpu_id = -1  # Set to -1 if you use CPU\n",
    "\n",
    "model = MLP()\n",
    "if gpu_id >= 0:\n",
    "    model.to_gpu(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 10\n",
    "\n",
    "# Wrap your model by Classifier and include the process of loss calculation within your model.\n",
    "# Since we do not specify a loss function here, the default 'softmax_cross_entropy' is used.\n",
    "model = L.Classifier(model)\n",
    "\n",
    "# selection of your optimizing method\n",
    "optimizer = optimizers.MomentumSGD()\n",
    "\n",
    "# Give the optimizer a reference to the model\n",
    "optimizer.setup(model)\n",
    "\n",
    "# Get an updater that uses the Iterator and Optimizer\n",
    "updater = training.updaters.StandardUpdater(train_iter, optimizer, device=gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a Trainer\n",
    "trainer = training.Trainer(updater, (max_epoch, 'epoch'), out='mnist_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chainer.training import extensions\n",
    "\n",
    "trainer.extend(extensions.LogReport())\n",
    "trainer.extend(extensions.snapshot(filename='snapshot_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.snapshot_object(model.predictor, filename='model_epoch-{.updater.epoch}'))\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/loss', 'main/accuracy', 'validation/main/loss', 'validation/main/accuracy', 'elapsed_time']))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.PlotReport(['main/accuracy', 'validation/main/accuracy'], x_key='epoch', file_name='accuracy.png'))\n",
    "trainer.extend(extensions.DumpGraph('main/loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/loss   main/accuracy  validation/main/loss  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           0.543687    0.850263       0.261991              0.92504                   23.6362       \n",
      "\u001b[J2           0.232927    0.932303       0.204056              0.939181                  47.2397       \n",
      "\u001b[J3           0.181096    0.947195       0.152571              0.956586                  70.6269       \n",
      "\u001b[J4           0.146535    0.957549       0.131982              0.961531                  94.0139       \n",
      "\u001b[J5           0.12275     0.963919       0.120622              0.964794                  117.384       \n",
      "\u001b[J6           0.107161    0.968733       0.113253              0.965487                  140.917       \n",
      "\u001b[J7           0.0925417   0.973364       0.103056              0.971222                  164.786       \n",
      "\u001b[J8           0.0812976   0.975578       0.0975507             0.971519                  188.055       \n",
      "\u001b[J9           0.0726222   0.978911       0.0878382             0.973398                  211.594       \n",
      "\u001b[J10          0.0657412   0.980877       0.0847919             0.976167                  234.979       \n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
